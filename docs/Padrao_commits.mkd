
---

# Estratégia de Commits — Coletor TRF5

## 1) Objetivo

Garantir que **cada merge entregue valor executável** e **não dependa de funcionalidades inacabadas**, com testes **E2E em ambiente real** (TRF5) antes de qualquer integração.

## 2) Modelo de branches (Git Flow enxuto)

* `main`: estável e versionada (tags semânticas). Apenas merges **após aceite do MVP** ou hotfix crítico.
* `develop`: integração contínua. Deve **sempre rodar** os três fluxos básicos: NPU (1 caso), CNPJ (1 página com limites), offline (amostra).
* `feature/<slug>`: uma funcionalidade, curto prazo, criada a partir de `develop`.
* `hotfix/<slug>`: correção urgente criada a partir de `main` (merge em `main` e `develop`).

**Políticas**

* Merge de `feature/*` é **squash-merge** em `develop`.
* Um `feature/*` **não** entra se **qualquer** portão E2E falhar.
* WIP pode ter commits pequenos; o merge deve resultar em **1–3 commits coesos**.

## 3) Mapa de dependências (DAG de funcionalidades)

Use os IDs abaixo para tomar decisões. Uma funcionalidade **só pode ser integrada** quando ela própria e **todas as suas dependências** estiverem concluídas e validadas em ambiente real.

| ID  | Funcionalidade                                                                                   | Depende de                                      |
| --- | ------------------------------------------------------------------------------------------------ | ----------------------------------------------- |
| F1  | Bootstrap do projeto (estrutura, `settings.py`, `requirements.txt`, variáveis `.env.example`)    | —                                               |
| F2  | Pipeline Mongo (conexão, persistência `raw_pages`)                                               | F1                                              |
| F3  | Spider NPU – **fetch detalhe** e salvar `raw_pages(tipo="detalhe")`                              | F2                                              |
| F4  | **Parser de detalhe** → `processos` (upsert idempotente por NPU)                                 | F3                                              |
| F5  | NPU – **idempotência validada** (2ª execução vira update)                                        | F4                                              |
| F6  | Spider CNPJ – **submissão do formulário** (lista) e salvar `raw_pages(tipo="lista")`             | F2                                              |
| F7  | **Paginação robusta** (Total\:N e/ou barra de páginas)                                           | F6                                              |
| F8  | CNPJ – **seguir detalhes** da lista (limites: `max_pages`, `max_details_per_page`) → `processos` | F4, F7                                          |
| F9  | Spider `parse_raw` – **reprocesso offline** a partir de `raw_pages(tipo="detalhe")`              | F4                                              |
| F10 | Documentação e scripts (README, runbook, wrappers)                                               | F1–F9 (pode ser incremental; concluir ao final) |

> Regra: **se “A” depende de “B”** e **“B” não depende de mais ninguém**, você pode integrar **A e B juntos** em um único merge **desde que os portões de validação E2E passem**. Nunca integre “A” sem “B”.

## 4) Definição de “Pronto para Commit” (DRC) por funcionalidade

### F1 — Bootstrap

**DRC-F1**

* `scrapy list` exibe `trf5` e `parse_raw`.
* `settings.py` com `ROBOTSTXT_OBEY=True`, `DOWNLOAD_DELAY>=0.5`, `AUTOTHROTTLE_ENABLED=True`.
* `.env.example` contém `MONGO_URI` e `MONGO_DB`.

### F2 — Pipeline Mongo (`raw_pages`)

**DRC-F2**

* Executar `scrapy crawl trf5 -a modo=numero -a valor="<NPU válido>" -s LOG_LEVEL=INFO`.
* Resultado: documento em `raw_pages` com `context.tipo="detalhe"` (mesmo que ainda sem item em `processos`).
* Sem exceções de conexão Mongo.

### F3 — NPU (detalhe → `raw_pages`)

**DRC-F3**

* `scrapy crawl trf5 -a modo=numero -a valor="<NPU válido>"`.
* `raw_pages` contém a página de **detalhe** do NPU com `status:200` e `html` não vazio.

### F4 — Parser de detalhe (→ `processos`)

**DRC-F4**

* Mesmo comando do F3.
* `processos` recebe o item com os **campos obrigatórios** do PRD (datas normalizadas ISO, `relator` apenas nome).
* `upsert` sem duplicidade (mesmo `_id`).

### F5 — Idempotência NPU

**DRC-F5**

* Executar o mesmo NPU **duas vezes**.
* 1ª execução: log de “insert”; 2ª: “update”; `processos` permanece **1** documento para o `_id`.

### F6 — CNPJ (lista → `raw_pages`)

**DRC-F6**

* `scrapy crawl trf5 -a modo=cnpj -a valor="00.000.000/0001-91" -a max_pages=1 -a max_details_per_page=1`.
* `raw_pages` recebe ao menos **uma** página de **lista** com `context.tipo="lista"` e `context.page_idx=0`.

### F7 — Paginação robusta

**DRC-F7**

* `scrapy crawl trf5 -a modo=cnpj -a valor="00.000.000/0001-91" -a max_pages=2 -a max_details_per_page=0`.
* Logs mostram detecção de **Total\:N** **ou** barra de páginas, e as duas páginas de lista são salvas (quando existirem).
* `raw_pages` contém `page_idx` coerente.

### F8 — CNPJ (seguir detalhes → `processos`)

**DRC-F8**

* `scrapy crawl trf5 -a modo=cnpj -a valor="00.000.000/0001-91" -a max_pages=2 -a max_details_per_page=3`.
* Para cada página de lista, até 3 detalhes salvos em `raw_pages` e itens gerados/atualizados em `processos`.
* Respeito a limites e logs claros.

### F9 — Reprocesso offline

**DRC-F9**

* `scrapy crawl parse_raw -a limit=10 -s LOG_LEVEL=INFO`.
* Logs: “Reprocessando {url}…” e “Processo atualizado: {NPU}”.
* Nenhuma requisição à rede.

### F10 — Documentação/Scripts

**DRC-F10**

* `README` cobre execução real para NPU, CNPJ e offline, além de consultas `mongosh`.
* Scripts `run_npu.sh`, `run_cnpj.sh`, `reprocess_offline.sh` e `mongo_queries.sh` funcionam.

## 5) Portões de validação (antes de merge em `develop`)

Para **qualquer** `feature/*`, executar localmente:

1. **Smoke NPU**

   ```
   scrapy crawl trf5 -a modo=numero -a valor="0015648-78.1999.4.05.0000" -s LOG_LEVEL=INFO
   ```

   * Esperado: `raw_pages(tipo="detalhe")`, item em `processos`.

2. **Smoke CNPJ (limites mínimos)**

   ```
   scrapy crawl trf5 -a modo=cnpj -a valor="00.000.000/0001-91" -a max_pages=1 -a max_details_per_page=1 -s LOG_LEVEL=INFO
   ```

   * Esperado: `raw_pages(tipo="lista")` e **ao menos 1** detalhe seguido.

3. **Offline (amostra)**

   ```
   scrapy crawl parse_raw -a limit=5 -s LOG_LEVEL=INFO
   ```

   * Esperado: atualizações em `processos` via HTML salvo.

Se qualquer um falhar por causa da alteração da branch, **não integrar**.

## 6) Padrão de mensagens (Conventional Commits)

* `feat(trf5-npu): parser de detalhe e upsert em processos`
* `feat(cnpj): seguir detalhes com limites por página`
* `fix(parser): remover prefixos do nome do relator`
* `refactor(normalize): padronizar ISO-8601 para datas`
* `docs(runbook): comandos de verificação no mongosh`
* `chore(settings): ajustar DOWNLOAD_DELAY para 0.7s`

**Assinatura recomendada**: `Signed-off-by: Nome <email>`
**Escopo** (`feat(<escopo>)`) deve apontar módulo/arquivo ou fluxo funcional.

## 7) Regras de integração e qualidade

* **Atomicidade**: cada merge deve habilitar **pelo menos um** fluxo de negócio completo (mesmo que parcial no escopo, mas executável).
* **Sem dead code**: não deixar trechos referenciando funções que ainda não existem em `develop`.
* **Fallbacks**: onde houver variação de layout, deixar `try/except` com log claro.
* **Configuração**: nada hardcoded de credenciais; usar `.env` (exemplo em `config/.env.example`).
* **Rebase**: manter `feature/*` atualizado com `develop` via `git pull --rebase`.
* **Squash**: consolidar antes do merge para manter o histórico limpo.

## 8) Critérios para release em `main`

* F1–F9 integrados e passando os portões de validação.
* `README` e `docs/runbook.md` atualizados.
* Criar tag semântica: `v1.0.0` (MVP).
* Para correções urgentes: `hotfix/*` a partir de `main`, validação rápida (NPU e offline), tag `v1.0.1`, e **merge de volta** em `develop`.

## 9) Como decidir se posso commitar agora?

1. **Liste as dependências** da sua funcionalidade usando a tabela do item 3.
2. **Confirme** que todas as dependências estão:

   * Integradas em `develop`, **ou**
   * Serão integradas **junto** no mesmo merge (desde que você prove os portões E2E).
3. **Rode os três portões**.
4. Se tudo passar, **squash-merge em `develop`**.
5. Se algum portão falhar **por causa da sua mudança**, **não integre** até corrigir.

## 10) Exemplos de decisões

* **Posso integrar F4 sem F5?** Sim. F4 entrega parser útil e executável. F5 é apenas a validação explícita da idempotência.
* **Posso integrar F6 sem F7?** Sim, desde que a lista seja salva em `raw_pages` e o fluxo não quebre sem paginação robusta.
* **Posso integrar F8 sem F7?** **Não.** Seguir detalhes da lista exige paginação estável para navegar múltiplas páginas.
* **Posso integrar F9 antes de F8?** Sim, desde que já existam `raw_pages(tipo="detalhe")` oriundas do F3/F4.

---

## 11) Checklist rápido para o autor do merge

* [ ] Branch criada a partir de `develop` e atualizada (rebase).
* [ ] DRC da(s) funcionalidade(s) atendido(s).
* [ ] Portões E2E (NPU, CNPJ com limites, offline) passaram.
* [ ] Mensagens de commit no padrão (Conventional Commits).
* [ ] Documentação atualizada quando aplicável.
* [ ] Squash-merge em `develop`.

---

Este documento define **políticas de decisão**, não uma linha do tempo rígida. Ele permite que o agente (Claude Code) avalie **dependências, portões E2E** e **critérios de prontidão** a cada alteração, garantindo que nenhum merge dependa de partes incompletas.
